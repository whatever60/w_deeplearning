{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0d1bdbded72f024b9331ead61a2f217ed72f340e06ce2ab6198f65373f5944641",
   "display_name": "Python 3.8.5 64-bit ('anaconda3': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Operations on Pytorch Tensor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method InteractiveShell.excepthook of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f9bd2899d60>>"
      ]
     },
     "metadata": {},
     "execution_count": 260
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from rich import print\n",
    "from rich.traceback import install\n",
    "install()"
   ]
  },
  {
   "source": [
    "## `select`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on method_descriptor:\n\nselect(...)\n    select(dim, index) -> Tensor\n    \n    Slices the :attr:`self` tensor along the selected dimension at the given index.\n    This function returns a view of the original tensor with the given dimension removed.\n    \n    Args:\n        dim (int): the dimension to slice\n        index (int): the index to select with\n    \n    .. note::\n    \n        :meth:`select` is equivalent to slicing. For example,\n        ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n        ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n\n"
     ]
    }
   ],
   "source": [
    "help(torch.Tensor.select)"
   ]
  },
  {
   "source": [
    "`select` method is equivalent  to indexing. They both return view and don't create new tensors."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "a = torch.randn(10, 128, requires_grad=True)\n",
    "b = a.select(1, 100)\n",
    "c = a[:, 100]\n",
    "print((b == c).all())\n",
    "print(b.data_ptr() == c.data_ptr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[91m╭─\u001b[0m\u001b[91m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[91m ───────────────────────────\u001b[0m\u001b[91m─╮\u001b[0m\n\u001b[91m│\u001b[0m \u001b[33m<ipython-input-189-e348ac35a4e8>\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                            \u001b[91m│\u001b[0m\n\u001b[91m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mRuntimeError: \u001b[0ma leaf Variable that requires grad is being used in an in-place operation.\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────╮</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-189-e348ac35a4e8&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>a leaf Variable that requires grad is being used in an in-place operation.\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "a -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "b -= 1\n",
    "print((c == b).all())  # inplace operation on `b` also affect `c`\n",
    "print(b.requires_grad)"
   ]
  },
  {
   "source": [
    "But `select` is slightly faster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.84 µs ± 297 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "7.3 µs ± 289 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a.select(1, 100)\n",
    "%timeit a[:, 100]"
   ]
  },
  {
   "source": [
    "## `index_select`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on built-in function index_select:\n\nindex_select(...)\n    index_select(input, dim, index, *, out=None) -> Tensor\n    \n    Returns a new tensor which indexes the :attr:`input` tensor along dimension\n    :attr:`dim` using the entries in :attr:`index` which is a `LongTensor`.\n    \n    The returned tensor has the same number of dimensions as the original tensor\n    (:attr:`input`).  The :attr:`dim`\\ th dimension has the same size as the length\n    of :attr:`index`; other dimensions have the same size as in the original tensor.\n    \n    .. note:: The returned tensor does **not** use the same storage as the original\n              tensor.  If :attr:`out` has a different shape than expected, we\n              silently change it to the correct shape, reallocating the underlying\n              storage if necessary.\n    \n    Args:\n        input (Tensor): the input tensor.\n        dim (int): the dimension in which we index\n        index (LongTensor): the 1-D tensor containing the indices to index\n    \n    Keyword args:\n        out (Tensor, optional): the output tensor.\n    \n    Example::\n    \n        >>> x = torch.randn(3, 4)\n        >>> x\n        tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],\n                [-0.4664,  0.2647, -0.1228, -1.1068],\n                [-1.1734, -0.6571,  0.7230, -0.6004]])\n        >>> indices = torch.tensor([0, 2])\n        >>> torch.index_select(x, 0, indices)\n        tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],\n                [-1.1734, -0.6571,  0.7230, -0.6004]])\n        >>> torch.index_select(x, 1, indices)\n        tensor([[ 0.1427, -0.5414],\n                [-0.4664, -0.1228],\n                [-1.1734,  0.7230]])\n\n"
     ]
    }
   ],
   "source": [
    "help(torch.index_select)"
   ]
  },
  {
   "source": [
    "`index_select` is similar to indexing, but there are three differences:\n",
    "\n",
    "- `index_select` creates new tensors.\n",
    "- index of `index_select` must be on the same device as the tensor.\n",
    "- `index_select` is slightly faster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "cu\u001b[1;92mda:0\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;92mTrue\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-281-f57d6fb630a1>:9: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n  print(b.grad is c.grad is None)  # Accessing grad of either will trigger UserWarning.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;91mFalse\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "a = torch.randn(10, 3, 32, 32, requires_grad=True)\n",
    "a.grad = torch.randn(10, 3, 32, 32)\n",
    "a = a.cuda()\n",
    "# For `index_select`, input, output and indices must be on the current device\n",
    "b = torch.index_select(a, torch.tensor(2).cuda(), torch.tensor([2,4,6]).cuda())\n",
    "print(b.device)\n",
    "c = a[:, :, [2, 4, 6]]  # But no such requirement for indexing\n",
    "print((b == c).all())\n",
    "print(b.grad is c.grad is None)  # Accessing grad of either will trigger UserWarning.\n",
    "print(b.data_ptr() == c.data_ptr())"
   ]
  },
  {
   "source": [
    "## `index_copy_`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on method_descriptor:\n\nindex_copy_(...)\n    index_copy_(dim, index, tensor) -> Tensor\n    \n    Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n    the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n    and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n    ``j``\\ th row of :attr:`self`.\n    \n    The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n    length of :attr:`index` (which must be a vector), and all other dimensions must\n    match :attr:`self`, or an error will be raised.\n    \n    Args:\n        dim (int): dimension along which to index\n        index (LongTensor): indices of :attr:`tensor` to select from\n        tensor (Tensor): the tensor containing values to copy\n    \n    Example::\n    \n        >>> x = torch.zeros(5, 3)\n        >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n        >>> index = torch.tensor([0, 4, 2])\n        >>> x.index_copy_(0, index, t)\n        tensor([[ 1.,  2.,  3.],\n                [ 0.,  0.,  0.],\n                [ 7.,  8.,  9.],\n                [ 0.,  0.,  0.],\n                [ 4.,  5.,  6.]])\n\n"
     ]
    }
   ],
   "source": [
    "help(torch.Tensor.index_copy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[91m╭─\u001b[0m\u001b[91m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[91m ───────────────────────────\u001b[0m\u001b[91m─╮\u001b[0m\n\u001b[91m│\u001b[0m \u001b[33m<ipython-input-111-db604107b90a>\u001b[0m:\u001b[94m3\u001b[0m in \u001b[92m<module>\u001b[0m                                            \u001b[91m│\u001b[0m\n\u001b[91m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mRuntimeError: \u001b[0ma leaf Variable that requires grad is being used in an in-place operation.\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────╮</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-111-db604107b90a&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>a leaf Variable that requires grad is being used in an in-place operation.\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "a = torch.randn(10, 3, 32, 32, requires_grad=True)\n",
    "b = torch.randn(10, 3, 2, 32, requires_grad=True)\n",
    "a.index_copy_(2, torch.tensor([20, 30]), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;91mFalse\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[33mIs data copied?\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Is data copied?</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[33mIs ptr copied?\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Is ptr copied?</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;91mFalse\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[33mMaybe ptr hasn't change?\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Maybe ptr hasn't change?</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[33mIs grad copied?\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Is grad copied?</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[33mHas data changed?\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Has data changed?</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[33mData remained the same?\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Data remained the same?</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "a = torch.randn(10, 3, 32, 32, requires_grad=True)\n",
    "a.grad = torch.randn(10, 3, 32, 32)\n",
    "c = torch.randn(10, 3, 2, 32, requires_grad=True)\n",
    "c.grad = torch.ones(10, 3, 2, 32)\n",
    "print(a.is_leaf)\n",
    "a[:, :, [20, 30]] = c\n",
    "print(a.is_leaf)\n",
    "data_cache = a[:, :, [20, 30]].clone()\n",
    "# do this after creating any new tensors, because ptr of `a` will change when creating new tensors\n",
    "ptr_cache = a[:, :, [20, 30]].data_ptr()\n",
    "\n",
    "print('[yellow]Is data copied?[/]')\n",
    "print((a[:, :, [20, 30]] == c).all())\n",
    "print('[yellow]Is ptr copied?[/]')\n",
    "print(a[:, :, [20, 30]].data_ptr() == c.data_ptr())\n",
    "print('[yellow]Maybe ptr hasn\\'t change?[/]')\n",
    "print(a[:, :, [20, 30]].data_ptr() == ptr_cache)  # ptr will change after initializing `c`\n",
    "print('[yellow]Is grad copied?[/]')\n",
    "print((a.grad[:, :, [20, 30]] == c.grad).all())  # grad is not copied\n",
    "\n",
    "# print('[yellow]Data remained the same?[/]')\n",
    "# c[:] -= 1\n",
    "# print((a[:, :, [20, 30]] == data_cache).all())\n",
    "\n",
    "optimizer = torch.optim.SGD([c], 0.1)\n",
    "optimizer.zero_grad()\n",
    "(c * 2).mean().backward()\n",
    "optimizer.step()\n",
    "print('[yellow]Has data changed?[/]')\n",
    "print((a[:, :, [20, 30]] == c).all())\n",
    "print('[yellow]Data remained the same?[/]')\n",
    "print((a[:, :, [20, 30]] == data_cache).all())  # data in `a` didn't change even if `c` has changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;91mFalse\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'RuntimeError'\u001b[0m\u001b[1m>\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'RuntimeError'</span><span style=\"font-weight: bold\">&gt;</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;91mFalse\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "c = torch.randn(10, 3, 2, 32, requires_grad=True)\n",
    "\n",
    "print(c.is_leaf)  # True\n",
    "print((c - 1).is_leaf)  # False\n",
    "\n",
    "c.data -= 1\n",
    "print(c.is_leaf)  # True\n",
    "print(c[:].data_ptr() == c.data_ptr())  # True\n",
    "try:\n",
    "    c -= 1\n",
    "except RuntimeError:\n",
    "    print(RuntimeError)\n",
    "\n",
    "c[:] -= 1\n",
    "print(c.is_leaf)  # False\n",
    "print(c[:].data_ptr() == c.data_ptr())  # True\n",
    "c -= 1  # This won't raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;91mFalse\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "c = torch.randn(10, 3, 2, 32, requires_grad=True)\n",
    "d = c.detach()\n",
    "print(d.requires_grad)\n",
    "print(d.data_ptr() == c.data_ptr())\n",
    "d -= 1\n",
    "print((d == c).all())\n",
    "print(c.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'RuntimeError'\u001b[0m\u001b[1m>\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'RuntimeError'</span><span style=\"font-weight: bold\">&gt;</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'RuntimeError'\u001b[0m\u001b[1m>\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'RuntimeError'</span><span style=\"font-weight: bold\">&gt;</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'RuntimeError'\u001b[0m\u001b[1m>\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'RuntimeError'</span><span style=\"font-weight: bold\">&gt;</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'RuntimeError'\u001b[0m\u001b[1m>\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'RuntimeError'</span><span style=\"font-weight: bold\">&gt;</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;91mFalse\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;92mTrue\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "c = torch.randn(10, 3, 2, 32, requires_grad=True)\n",
    "print(c.is_leaf)\n",
    "try:\n",
    "    c += 1  # RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
    "except RuntimeError:\n",
    "    print(RuntimeError)\n",
    "try:\n",
    "    torch.add(c, 1, out=c)  # RuntimeError: add(): functions with out=... arguments don't support automatic differentiation, but one of the arguments requires grad. Grad will not be copied (only data will be copied).\n",
    "except RuntimeError:\n",
    "    print(RuntimeError)\n",
    "try:\n",
    "    c.add_(1)  # RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
    "except RuntimeError:\n",
    "    print(RuntimeError)\n",
    "try:\n",
    "    c.index_copy_(3, torch.tensor(10), torch.randn(10, 3, 2, 1))  # RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.\n",
    "except RuntimeError:\n",
    "    print(RuntimeError)\n",
    "d = c.detach()\n",
    "d += 1  # no error, and still leaf\n",
    "print(c.is_leaf)\n",
    "c[:] += 1  # no error, but not leaf anymore\n",
    "print(c.is_leaf)\n",
    "print(c.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1;36m-0.15784788\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.15784788</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[1;36m-0.1578\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSelectBackward\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1578</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SelectBackward</span><span style=\"font-weight: bold\">&gt;)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[1;36m-1.1578479\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1578479</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[1;36m-1.1578\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSelectBackward\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1578</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SelectBackward</span><span style=\"font-weight: bold\">&gt;)</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "e = c.detach().numpy()\n",
    "print(e[0,0,0,0])\n",
    "print(c[0,0,0,0])\n",
    "e -= 1\n",
    "print(e[0,0,0,0])\n",
    "print(c[0,0,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Grad will not be copied (only data will be copied)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tensor\u001b[1m(\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "a = torch.randn(10, 3, 32, 32, requires_grad=False)\n",
    "b = torch.randn(10, 3, 2, 32, requires_grad=True)\n",
    "a.grad = torch.randn(10, 3, 32, 32)\n",
    "grad_cache = a.grad[:, :, [20, 30]].clone()\n",
    "b.grad = torch.ones(10, 3, 2, 32)\n",
    "a.index_copy_(2, torch.tensor([20, 30]), b)\n",
    "print((a.grad[:, :, [20, 30]] == b.grad).all())\n",
    "print((a.grad[:, :, [20, 30]] == grad_cache).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;35mNone\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n</pre>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-114-28c7d4e1cc1b>:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n  print(a.grad)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;35mNone\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "a = torch.randn(10, 3, 32, 32, requires_grad=False)\n",
    "b = torch.randn(10, 3, 2, 32, requires_grad=True)\n",
    "print(a.grad)\n",
    "b.grad = torch.randn(10, 3, 2, 32)\n",
    "a.index_copy_(2, torch.tensor([20, 30]), b)\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;35mNone\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "a = torch.randn(3,4,5)\n",
    "print(a.grad)\n",
    "b = torch.randn(3,5, requires_grad=True)\n",
    "a[:, 0] = b.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "\u001b[3;35mNone\u001b[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n</pre>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}